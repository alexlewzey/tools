{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab probs * prediction index\n",
    "probs = np.random.dirichlet(np.ones(5), 10)\n",
    "y = probs.argmax(1)\n",
    "probs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complexity if all predictions are correct\n",
    "complexity = np.exp(-np.log(probs[range(len(probs)), y]).mean())\n",
    "complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complexity if actual labels are random\n",
    "y_rand = np.random.randint(10)\n",
    "complexity = np.exp(-np.log(probs[range(len(probs)), y_rand]).mean())\n",
    "complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1\n",
    "weights = np.random.random((10, 10))\n",
    "a = np.random.random((10, rank))\n",
    "b = np.random.random((rank, 10))\n",
    "assert (a @ b).shape == weights.shape\n",
    "weights, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total parameters, decomposed parameters\n",
    "weights.flatten().shape[0], len(a) + len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = 0.1\n",
    "weights_new = weights + (a @ b) * scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"cat\": np.array([1, 0, 0, 0]),\n",
    "    \"dog\": np.array([0, 1, 0, 0]),\n",
    "    \"is\": np.array([0, 0, 1, 0]),\n",
    "    \"black\": np.array([0, 0, 0, 1]),\n",
    "}\n",
    "sentence = [\"cat\", \"is\", \"black\"]\n",
    "input_embeddings = np.array([vocab[word] for word in sentence])\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prompt_tokens = 2\n",
    "prompt_embeddings = np.random.randn(num_prompt_tokens, 4)\n",
    "combined = np.vstack([prompt_embeddings, input_embeddings])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**32 / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass and update the virtual tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
